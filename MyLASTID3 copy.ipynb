{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "from IPython.display import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>Urea</th>\n",
       "      <th>HbA1c (Sugar level)</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>HDL</th>\n",
       "      <th>BMI</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>7.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>21.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>60</td>\n",
       "      <td>4.9</td>\n",
       "      <td>10.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>60</td>\n",
       "      <td>2.1</td>\n",
       "      <td>12.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>61</td>\n",
       "      <td>7.1</td>\n",
       "      <td>13.6</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>63</td>\n",
       "      <td>2.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>55</td>\n",
       "      <td>5.1</td>\n",
       "      <td>9.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AGE  Urea  HbA1c (Sugar level)  Cholesterol  HDL   BMI CLASS \n",
       "0     50   4.7                  4.9          4.2  2.4  24.0      N\n",
       "1     26   4.5                  4.9          3.7  1.1  23.0      N\n",
       "2     50   4.7                  4.9          4.2  2.4  24.0      N\n",
       "3     50   4.7                  4.9          4.2  2.4  24.0      N\n",
       "4     33   7.1                  4.9          4.9  0.8  21.0      N\n",
       "..   ...   ...                  ...          ...  ...   ...    ...\n",
       "795   60   4.9                 10.2          3.9  1.3  29.0      Y\n",
       "796   60   2.1                 12.3          6.2  1.0  30.0      Y\n",
       "797   61   7.1                 13.6          6.6  1.1  31.0      Y\n",
       "798   63   2.8                 11.2          4.2  1.7  36.0      Y\n",
       "799   55   5.1                  9.7          3.2  1.0  33.0      Y\n",
       "\n",
       "[800 rows x 7 columns]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/mdrizwanulaminadmin/RINTS/UTS/Machine learning /800diabetes.csv\")\n",
    "#df = pd.read_csv(\"/Users/mdrizwanulaminadmin/RINTS/UTS/Machine learning /capstone2.csv\")\n",
    "#df = df.drop(['ID','No_Pation','Gender'],axis=1) \n",
    "#df = df.iloc[:, :-1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "Y = df.iloc[:, -1].values.reshape(-1,1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size=0.2, random_state = 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, feature_index=None, threshold=None, left_Node=None, right_Node=None, info_gain=None, value=None):\n",
    "        \n",
    "        self.feature_index = feature_index     # for decision node\n",
    "        self.threshold = threshold\n",
    "        self.left_Node = left_Node\n",
    "        self.right_Node = right_Node\n",
    "        self.info_gain = info_gain\n",
    "        \n",
    "        self.value = value                    # leaf node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ID3_Classifier():\n",
    "\n",
    "    def __init__(self, min_samples_split = None, max_depth = None):\n",
    "        \n",
    "        self.root = None\n",
    "\n",
    "        self.min_samples_split = min_samples_split\n",
    "        \n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def build_tree(self, dataset, current_depth=0):\n",
    "\n",
    "        X, Y = dataset[:,:-1], dataset[:,-1]\n",
    "        num_samples, num_features = np.shape(X)\n",
    "\n",
    "        if num_samples >= self.min_samples_split and current_depth <= self.max_depth:\n",
    "            \n",
    "            best_split = self.find_best_split(dataset, num_samples, num_features)\n",
    "            \n",
    "            if best_split[\"info_gain\"]>0:\n",
    "                \n",
    "                left_subtree = self.build_tree(best_split[\"left_dataset\"], current_depth +1)\n",
    "                \n",
    "                right_subtree = self.build_tree(best_split[\"right_dataset\"], current_depth +1)\n",
    "                \n",
    "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"], left_subtree, right_subtree, best_split[\"info_gain\"])\n",
    "    \n",
    "        \n",
    "        leaf_Value = self.calculate_leaf_Value(Y)\n",
    "        # return leaf node\n",
    "        return Node(value=leaf_Value)\n",
    "    \n",
    "    def find_best_split(self, dataset, num_samples, num_features):\n",
    "        \n",
    "        best_split = {}\n",
    "        #best_info_gain = -float(\"inf\")\n",
    "        best_info_gain = -1\n",
    "        \n",
    "        for feature_index in range(num_features):\n",
    "\n",
    "            feature_Values = dataset[:, feature_index]\n",
    "            freq_Values = np.unique(feature_Values)\n",
    "            \n",
    "            for threshold in freq_Values:\n",
    "\n",
    "                left_dataset = np.array([row for row in dataset if row[feature_index]<=threshold])\n",
    "\n",
    "                right_dataset = np.array([row for row in dataset if row[feature_index]>threshold])\n",
    "                \n",
    "                if len(left_dataset)>0 and len(right_dataset)>0:\n",
    "\n",
    "                    y, left_data_y, right_data_y = dataset[:, -1], left_dataset[:, -1], right_dataset[:, -1]\n",
    "\n",
    "                    info_gain = self.information_Gain(y, left_data_y, right_data_y, mode=\"entropy\")\n",
    "                    \n",
    "                    if  info_gain > best_info_gain:                        # update \n",
    "                        best_split[\"feature_index\"] = feature_index\n",
    "                        best_split[\"threshold\"] = threshold\n",
    "                        best_split[\"left_dataset\"] = left_dataset\n",
    "                        best_split[\"right_dataset\"] = right_dataset\n",
    "                        best_split[\"info_gain\"] = info_gain\n",
    "                        best_info_gain = info_gain\n",
    "        \n",
    "        return best_split\n",
    "    \n",
    "    def information_Gain(self, parent, left_child, right_child, mode = \"entropy\"):\n",
    "        \n",
    "        weight_left = len(left_child) / len(parent)\n",
    "        weight_right = len(right_child) / len(parent)\n",
    "        \n",
    "        return self.entropy(parent) - (weight_left*self.entropy(left_child) + weight_right*self.entropy(right_child))\n",
    "         \n",
    "    \n",
    "    def entropy(self, y):\n",
    "        \n",
    "        target_classes = np.unique(y)\n",
    "        entropy = 0\n",
    "        for Class in target_classes:\n",
    "\n",
    "            p_Class = len(y[y == Class]) / len(y)\n",
    "\n",
    "            entropy += -(p_Class * np.log2(p_Class))\n",
    "            #entropy += -p_Class * np.log2(p_Class)\n",
    "\n",
    "        return entropy\n",
    "       \n",
    "    def calculate_leaf_Value(self, Y):                     # ''' function to compute leaf node '''\n",
    "        \n",
    "        Y = list(Y)\n",
    "        \n",
    "        return max(Y, key = Y.count)\n",
    "\n",
    "    \n",
    "    def print_Tree(self, tree=None, indent=\" \"):\n",
    "\n",
    "        feature_names = np.array(['AGE', 'Urea', 'HbA1c (Sugar level)', 'Cholesterol', 'HDL', 'BMI'])\n",
    "\n",
    "        if tree is None:\n",
    "            tree = self.root\n",
    "\n",
    "        if tree.value is not None:\n",
    "            if tree.value in [\"N\", \"Y\", \"P\"]:            # list of target classes \n",
    "                print(f\"Leaf Node: {tree.value}\")\n",
    "            else:\n",
    "                print(f\"Leaf Node: Class {tree.value}\")\n",
    "        else:\n",
    "            feature_name = feature_names[tree.feature_index] if tree.feature_index is not None else \"Unknown\"\n",
    "\n",
    "            print(f\"Decision Node: {feature_name} <= {tree.threshold} (Info Gain: {tree.info_gain})\")\n",
    "            print(f\"{indent}Left:\")\n",
    "            self.print_Tree(tree.left_Node, indent + \"  \")\n",
    "            print(f\"{indent}Right:\")\n",
    "            self.print_Tree(tree.right_Node, indent + \"  \")\n",
    "\n",
    "    def fit(self, X, Y):                              #''' function to train the tree '''\n",
    "                                              \n",
    "        dataset = np.concatenate((X, Y), axis=1)\n",
    "        self.root = self.build_tree(dataset, current_depth = 0)\n",
    "    \n",
    "    def predict(self, X):                             #''' function to predict new dataset '''\n",
    "        \n",
    "        preditions = [self.make_prediction(x, self.root) for x in X]\n",
    "        \n",
    "        return preditions\n",
    "    \n",
    "    def make_prediction(self, x, tree):\n",
    "        \n",
    "        if tree.value != None: return tree.value\n",
    "        \n",
    "        else:\n",
    "            feature_val = x[tree.feature_index]\n",
    "            if feature_val <= tree.threshold:\n",
    "                return self.make_prediction(x, tree.left_Node)\n",
    "            else:\n",
    "                return self.make_prediction(x, tree.right_Node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Node: BMI <= 25.0 (Info Gain: 0.5047650762174729)\n",
      " Left:\n",
      "Decision Node: HbA1c (Sugar level) <= 5.6 (Info Gain: 0.6904416791104199)\n",
      "   Left:\n",
      "Decision Node: Cholesterol <= 4.9 (Info Gain: 0.22005511305879277)\n",
      "     Left:\n",
      "Decision Node: BMI <= 24.6 (Info Gain: 0.3372900666170139)\n",
      "       Left:\n",
      "Leaf Node: N\n",
      "       Right:\n",
      "Leaf Node: Y\n",
      "     Right:\n",
      "Decision Node: Cholesterol <= 7.1 (Info Gain: 0.12148687778112766)\n",
      "       Left:\n",
      "Leaf Node: Y\n",
      "       Right:\n",
      "Leaf Node: N\n",
      "   Right:\n",
      "Decision Node: HbA1c (Sugar level) <= 6.4 (Info Gain: 0.6840384356390417)\n",
      "     Left:\n",
      "Leaf Node: P\n",
      "     Right:\n",
      "Leaf Node: Y\n",
      " Right:\n",
      "Decision Node: AGE <= 48.0 (Info Gain: 0.038015507838487)\n",
      "   Left:\n",
      "Decision Node: HbA1c (Sugar level) <= 6.3 (Info Gain: 0.6840384356390417)\n",
      "     Left:\n",
      "Leaf Node: P\n",
      "     Right:\n",
      "Leaf Node: Y\n",
      "   Right:\n",
      "Leaf Node: Y\n"
     ]
    }
   ],
   "source": [
    "classifier = ID3_Classifier(min_samples_split=3, max_depth=3)\n",
    "\n",
    "classifier.fit(X_train,Y_train)\n",
    "\n",
    "classifier.print_Tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.75%\n"
     ]
    }
   ],
   "source": [
    "Y_pred = classifier.predict(X_test) \n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)*100\n",
    "print(f\"Accuracy: {accuracy}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
